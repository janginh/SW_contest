

경진 대회 신청 기간 (3.21 ~ 6.9)
◎ 구현 계획 및 일정(구현 완성도 25점, 사용 가능성 10점)
 - 아이디어 구체화
 - 데이터 수집 및 모델 학습
 - 프로토타입 개발
 - 테스트 및 개선
 - 최종 발표 및 제출
기술 스택
GPT-4, LLAMA 모델 사용
RAG 방식 사용 : 데이터 학습

벡엔드 : Python + Flask
프론트 : React.js + Next.js, Express.js
데이터베이스 : PostgreSQL, MongoDB, Redis

[3.31]
- 아이디어 구체화 과정
 “사회적 문제 해결을 위한 생성형 AI 활용”이라는 주제에서 사회적 문제의 정의를 하기 위해 아이디어를 도출하는 브레인스토밍 과정을 진행하였습니다. 초기 단계에서는 ‘사회적 문제란 무엇인가’에 대해 토의를 진행하였으며, 이를 바탕으로 여러 아이디어를 수집하였습니다. 그 결과 팀원 모두가 공감한 “생성형AI를 활용한 학생들의 문해력 향상 프로그램”을 최종 아이디어로 정하게 되었습니다.
 아이디어를 구체화 하기 위해 체계적으로 접근하고자 하였습니다. 우선 육하원칙(누가, 무엇을, 언제, 어디서, 왜, 어떻게)을 이용하는 스타버스팅 기법을 활용하여 다양한 각도에서 아이디어를 분석 할 수 있었으며, 추가적으로 다음 항목을 중심으로 아이디어를 구체화 하였습니다.
 1. 현재 학생들의 문해력 저하가 왜 사회적 문제인지에 대한 정의
 2. 이를 해결하기 위한 생성형 AI의 역할 및 기대 효과
 3. 유사한 기존 프로그램의 사례 분석 및 차별점 도출
 4. 아이디어의 차별성과 기술적 실현 가능성 검토
 5. 추가적인 기능 요소 및 사용자 경험 향상 방안 모색
이러한 구체화 과정은 단순한 아이디어 수준에서 그치지 않고, 문제 해결의 효과성, 기술 구현의 현실성, 사용자 관점의 사용 가능성 등을 다각도로 검토하는 데 중점을 두었습니다. 결과적으로, 프로그램이 사회적 문제 해결에 실질적인 기여를 할 수 있는지를 생각하며 발전 방향을 도출하였습니다

- 구현 계획 및 일정
 팀원끼리 역할을 분담하여 크게 4가지로 구분하여 인공지능개발, 백엔드 개발, 프론트엔드개발, 데이터관리로 나누어 진행할 예정입니다. 서로의 협업을 위해서는 github를 활용하여 버전관리 및 코드를 교환하며 제작할 예정입니다. 예상 일정은 13주정도로 대략 3달정도를 예상하고 있습니다.
1단계 : 데이터 수집 및 모델 학습 (1~2주차)
 - 데이터 수집 (1주차) :
  • 국내 기관에서 제공하는 어휘 난이도 데이터
  • 국립 국어원, 교육부 제공하는 사전 데이터
  • 뉴스, 논문등에 자주 등장하는 어려운 단어 리스트
  • 저작권 검토 후 공개 라이선스 데이터 우선 사용
 - 데이터 학습 (2주차) :
  • KoNLPy, Pandas 등의 라이브러리 사용하여 텍스트 전처리후 학습
  • 기존 대형 언어 모델(GPT-4, LLaMA)을 fine-tuning으로 사용 목적에 맞춰 변경
  • 학습 성능 평가 : 정확성, 응답속도, 생성 품질성을 따져서 테스트

2단계 : 프로토타입 개발 (3~8주차) : 
 - 개발 1단계 : 개별적 파트 개발 위주 (3~5주차) : 1단계에서는 UX, UI 설계와 각 파트별로 초기 기능 개발이 중심이 되어 진행되어야합니다.
  • 프론트엔드 개발 : UI/UX 개발, API 연동 테스트(로그인), 페이지 설계 및 기능 연결
  • 백엔드 개발 : Flask 프레임워크로 서버 설정, 기본 API 개발, 사용자 인증 시스템
  • 인공지능 개발 : 생성형 AI 모델 설계, 기본적인 응답 생성 테스트, KoNLPy활용한 자연어 처리, 어휘 난이도 분석 기능 개발
  • 데이터관리 : 데이터 추가 수집, 데이터 정규화(CSV, JSON으로 동일), 시스템과 데이터베이스 연동

 - 개발 2단계 : 협업 개발 및 AI 심화 (6~9주차) : 2단계에서는 파트별 통합이 시작되는 시기이기 때문에 통합 개발 환경이 구축되기 해야하며, 독립적으로 개발 하던 내용이 서로 연결이 가능하도록 수정하는 과정도 거쳐야합니다.
  • 프론트엔드 개발 : AI 대화 시각화(챗봇), 마이페이지 UI 생성, 페이지 응답 속도 개선
  • 백엔드 개발 : AI와 통신 API 제작, 학습 진도별 데이터 최신화 기능 추가
  • 인공지능 개발 : 성능개선(하이퍼파라미터 조정), 문해력 테스트 생성 구현, AI의 데이터 분석 기능 추가
  • 데이터 관리 : NER을 이용해 정보 검색 정밀도 향상, 필요 파트에 데이터 제공

 - 개발 3단계 : 통합 단계 (10~11주차) : 각 파트의 기능 통합, API통신 : 3단계에서는 모든 내용을 통합하여 완성하는 것이 목표로, 주요 포인트는 API 연결성입니다. 클라이언트와 서버와의 통신의 원활함이 주요 관건입니다.
  • 프론트엔드 : 클라이언트 – 서버 통신 연결, API 호출 결과 UI 개발
  • 백엔드 : API 엔드포인트 작성, AI 예측 결과 구축 API 생성, API 응답 속도 개선
  • 인공지능 개발 : 벡엔드 API에 AI 연결, AI API 테스트(데이터전달, 예측, 반환 과정 확인)
  • 데이터 관리 : 초기 데이터베이스 연결, 샘플 데이터 구축 테스트, 데이터 최신화, 조회, 삭제기능 구현

 - 테스트 및 개선 (2주) :
  • 테스트 항목 (1주) : 
   1. 기능 테스트 : 생성형 AI의 기능들이 정확하게 동작하는가
   2. 성능 테스트 : API 응답 속도, 서버 부하 테스트, AI 처리속도
   3. UX 테스트 : 사용자의 편의성, 직관성, 사용성, 반응성
   4. 사용 시나리오 : 사용자의 행동흐름에 맞추어 시나리오 작성
   5. 단위 테스트, 통합 테스트 : 파트별 기능에 대해 체크, 백엔드 프론트엔드 API 연동 테스트
  • 베타 테스트 및 피드백 수집 (1주) :
 다양한 사용자(학생, 교사, 일반인)가 직접 사용후 구글폼을 이용해 피드백 수집할 예정입니다. 우선 테스트 항목으로는 기능성, 사용성, 성능, 오류 및 버그로 4가지 항목을 중심으로 확인할 예정입니다. 추가적으로는 불편하거나 개선이 필요한 부분을 받아 적극적으로 의견을 수용할 생각입니다.

 - 최종 발표 및 제출 (1주) :
 발표 자료 준비를 위해 우선 발표 구성 단계를 만들 생각입니다. 가장 먼저 사회적문제에 대한 정의 다음으로는 해결 방법을 찾기 위해 아이디어를 모으는 과정, 해당 해결 방법을 정하게 된 이유, 기존의 해결방법과의 차별점 등을 설명할 생각입니다. 세번째로는 생성형 AI의 역할, AI를 만들기 위한 기술, 개발 과정들을 설명할 예정입니다. 그리고 네번째 프로토타입을 이용한 시연 영상과 해당 프로그램의 기대효과와 향후 발전 가능성, 실직적 교육 효과에 대해 설명하고자 합니다. 영상을 준비하는 이유는 가장 직관적으로 현재 프로그램이 어떤식으로 작동하는지에 대해 볼 수 있는 방법이기 때문에 영상 준비할 생각입니다. 마지막으로 질의응답 과정을 통해 준비하지 못한 부분에 대한 보충 설명으로 발표를 마무리할 생각입니다.
 마지막 질의응답 과정을 준비하기 위해 기술적 도전과제, 프로그램에서 예상되는 한계점, 프로토타입이 아닌 실제로 구현할 경우 예상되는 문제들에 대한 해결방법을 미리 준비할 생각입니다. 




 - 아이디어 구체화 (2주) :
"사회적 문제 해결을 위한 생성형 AI활용" 이라는 주제에 맞는 아이디어를 모으기 위해 처음에는 사회적 문제에는 무엇이 있을까 라는 내용을 시작으로 브레인 스토밍 시간을 통해 여러 아이디어를 종합하여 "생성형 AI를 활용한 학생들의 문해력 향상 프로그램"으로 정하게 되었습니다. 구체화 단계에서는 브레인 스토밍의 한가지 방법인 스타버스팅, 즉 육하원칙(누가, 무엇을, 언제, 어디서, 왜, 어떻게)을 이용해 구체적인 사회적 문제의 정의, 문제 해결방안, 프로그램의 예상효과등을 정리하고 기존에 해당 문제를 해결하기 위한 프로그램에는 어떤것이 존재하고, 해당 프로그램과 우리 아이디어의 차별점은 어떤점에서 다른지, 더 나은 대안책은 없을지, 새롭게 만들 부분은 없을지, 기술적으로 어떤 식으로 접근하면 좋을지를 고민하며 문제 해결 효과성, 구현 가능성, 사용 가능성의 기준을 토대로 적합성을 평가하며 구체화 할 생각입니다.

 -> 개발하기 위한 모든 아이디어 (프로그래밍 언어, 파트 구분 등의 내용의 구체화)
 -> 사회적문제를 중심으로 브레인스토밍 -> 결과가 나왔다?


- 수정사항 대체글
아이디어 구체화 과정

본 프로젝트는 "사회적 문제 해결을 위한 생성형 AI 활용"이라는 대주제 아래, 사회적 문제의 정의부터 시작하여 다양한 아이디어를 도출하는 브레인스토밍 과정을 거쳤습니다. 초기 단계에서는 ‘사회적 문제란 무엇인가’에 대해 팀원 간 폭넓은 논의를 진행하였고, 이를 바탕으로 여러 아이디어를 수집하였습니다. 그 결과, 팀원 모두가 공감할 수 있는 주제로서 **"생성형 AI를 활용한 학생들의 문해력 향상 프로그램"**을 최종 아이디어로 선정하였습니다.

아이디어 선정 이후에는 이를 구체화하기 위한 체계적인 접근이 필요했습니다. 이에 따라 **육하원칙(누가, 무엇을, 언제, 어디서, 왜, 어떻게)**을 활용한 스타버스팅 기법을 적용하여 문제의 정의와 맥락을 다각도로 분석하였습니다. 구체적으로는 다음과 같은 항목을 중심으로 내용을 정리하였습니다:

현재 학생들의 문해력 저하가 왜 사회적 문제인지에 대한 정의

이를 해결하기 위한 생성형 AI의 역할 및 기대 효과

유사한 기존 프로그램의 사례 분석 및 차별점 도출

아이디어의 차별성과 기술적 실현 가능성 검토

추가적인 기능 요소 및 사용자 경험 향상 방안 모색

이러한 구체화 과정은 단순한 아이디어 수준에서 그치지 않고, 문제 해결의 효과성, 기술 구현의 현실성, 사용자 관점의 사용 가능성 등을 다각도로 검토하는 데 중점을 두었습니다. 결과적으로, 본 프로그램이 사회적 문제 해결에 실질적인 기여를 할 수 있는지를 면밀히 평가하며 발전 방향을 도출하고 있습니다.

-> 따로 구분 없이 이어버리기,
이미 선정된 아이디어를 이용해서 계획을 작성해 나아간다.


 - 데이터 수집 및 모델 학습 (1달) :
 우선 인공지능을 가장 활용하기 편한 파이썬 언어를 기반으로 만들 예정이며, 우선 아이디어 맞는 생성형 AI를 만들기 위해 데이터를 수집해야합니다. 이를 위해 데이터 수집을 위해 국내 교육기관에서 제공하는 어휘 난이도 데이터, 국립 국어원과 교육부에서 제공하는 사전 데이터, 뉴스와 논문에서 자주 등장하는 어려운 단어 리스트 데이터들을 수집하고 KoNLPy 라이브러리를 활용하여 텍스트 전처리, 어휘 난위도 분석, 초성 퀴즈 만들기, 지문 분석및 요약등의 기능을 생성형 ai와 연동시켜 그저 생성형 ai만 활용하는 방법보다 속도적 측면이나 정확성 측면에서도 도움을 줄 수 있을것으로 예상됩니다. 데이터들에 대한 저작권에 대해서는 공개 라이선스 데이터를 우선적 사용으로 피할 예정이면 필요시에는 기관과의 협의 이후 데이터 사용 승인을 받을 생각입니다. 

 - 프로토타입 개발 (2달) : 
팀원끼리 역할을 분담하여 크게 4가지로 구분하여 인공지능개발, 백엔드 개발, 프론트엔드 개발, 데이터관리로 나누어 진행할 예정입니다. 
 ● 인공지능 개발 : GPT-4, LLAMA 기반의 생성형 AI 모델 설계 및 API 연동, 데이터학습
 ● 백엔드 개발: Flask를 사용해 서버 구축, API 개발, AI 모델과의 통신, 데이터베이스 설계, 보안 설정
 ● 프론트엔드 개발: CSS를 이용해 UI/UX 설계, React를 이용한 클라이언트-서버 통신, 사용자 인터페이스 개발
 ● 데이터 관리: 데이터 수집, 전처리, DB 설계, AI 학습용 데이터 제공
 협업을 효율적으로 하기 위해 github를 이용해 버전관리 및 서로 코드를 교환하며 제작할 예정입니다. github 사용 도중 코드 충돌 방지를 위해 작업 이력 관리 및 코드리뷰를 통해 충돌을 방지하고자 합니다. 
 예상 일정은 대략 9주 정도로 프로토타입 개발에 힘을 쓸 생각입니다. 3주 간격으로 개인별 개발, 두 개발자의 협업 개발, 세 개발자 모두 협업으로 이루어지고자 합니다.
 ● 1~3주차 : (UI/UX 설계가 최우선) UI설계 및 개발 시작, 기본 페이지 구성, 기본 API 구성, AI 기본 기능 개발, 데이터 수집
 ● 4~6주차 : (서로 협업이 필요한 부분을 개발) : AI의 데이터 분석기능, 백엔드 프론트 엔드의 연결
 ● 7~9주차 : (인공지능을 중심으로 모든 부분 연결) : 데이터베이스와 인공지능, 서버와 인공지능 연결, AI 모델의 최종 통합

-> 주차(일차)별이 중심으로 되도록 만들기
-> 

 - 테스트 및 개선 (2주) : 
 포로토타입 테스트를 위해서 AI생성 내용이 부적절하거나 AI와의 대화의 흐름이 이상하게 흐르거나 공격적 표현의 필터링을 먼저 확인 후 평가 기준을 만들어 응답속도, 정확도, 편의성, 직관성, 유효성을 기준으로 테스트를 진행할 것입니다. 팀원들의 의견으로는 부족 할 수 있기 때문에 베타테스트를 통해 다양한 사용자의 피드백을 수집하고 개선점을 찾아보고자 합니다. 

 - 최종 발표 및 제출(1주) : 
 발표 자료 준비를 위해 우선 발표 구성 단계를 만들 생각입니다. 가장 먼저 사회적문제에 대한 정의 다음으로는 해결 방법을 찾기 위해 아이디어를 모으는 과정, 해당 해결 방법을 정하게 된 이유, 기존의 해결방법과의 차별점 등을 설명할 생각입니다. 세번째로는 생성형 AI의 역할, AI를 만들기 위한 기술, 개발 과정들을 설명할 예정입니다. 그리고 네번째 프로토타입을 이용한 시연 영상과 해당 프로그램의 기대효과와 향후 발전 가능성, 실직적 교육 효과에 대해 설명하고자 합니다. 영상을 준비하는 이유는 가장 직관적으로 현재 프로그램이 어떤식으로 작동하는지에 대해 볼 수 있는 방법이기 때문에 영상 준비할 생각입니다. 마지막으로 질의응답 과정을 통해 준비하지 못한 부분에 대한 보충 설명으로 발표를 마무리할 생각입니다.
 마지막 질의응답 과정을 준비하기 위해 기술적 도전과제, 프로그램에서 예상되는 한계점, 프로토타입이 아닌 실제로 구현할 경우 예상되는 문제들에 대한 해결방법을 미리 준비할 생각입니다. 







(25.03.29)
아이디어 구체화 (2주) :
"사회적 문제 해결을 위한 생성형 AI활용" 이라는 주제에 맞는 아이디어를 모으기 위해 처음에는 사회적 문제에는 무엇이 있을까 라는 내용을 시작으로 브레인 스토밍 시간을 통해 여러 아이디어를 종합하여 팀원 모두가 만족하는 아이디어로 "생성형 AI를 활용한 학생들의 문해력 향상 프로그램"이라는 사회적 문제를 중심으로 하기로 정하게 되었다. 이제 주제는 다 정해졌으니 다음은 구체화 단계를 진행할 것이다. 구체화 단계에서는  브레인 스토밍의 한가지 방법인 스타버스팅, 즉 육하원칙(누가, 무엇을, 언제, 어디서, 왜, 어떻게)을 이용해 구체적인 사회적 문제의 정의, 문제 해결방안, 프로그램의 예상효과등을 정리하고 기존에 해당 문제를 해결하기 위한 프로그램에는 어떤것이 존재하고, 해당 프로그램과 우리 아이디어의 차별점은 어떤점에서 다른지, 더 나은 대안책은 없을지, 새롭게 만들 부분은 없을지, 기술적으로 어떤 식으로 접근하면 좋을지를 고민하며 문제 해결 효과성, 구현 가능성, 사용 가능성의 기준을 토대로 적합성을 평가하며 구체화 할 생각이다.

데이터 수집 및 모델 학습 (1달) :
 우선 인공지능을 가장 활용하기 편한 파이썬 언어를 기반으로 만들 예정이며, 우선 아이디어 맞는 생성형 AI를 만들기 위해 데이터를 수집해야한다. 데이터 수집을 위해 국내 교육기관에서 제공하는 어휘 난이도 데이터, 국립 국어원과 교육부에서 제공하는 사전 데이터, 뉴스와 논문에서 자주 등장하는 어려운 단어 리스트 데이터들을 수집하고 KoNLPy 라이브러리를 활용하여 텍스트 전처리, 어휘 난위도 분석, 초성 퀴즈 만들기, 지문 분석및 요약등의 기능을 생성형 ai와 연동시켜 그저 생성형 ai만을 활용하는 방법보다 속도적 측면이나 정확성 측면에서도 도움을 줄 수 있을것으로 예상된다. 
데이터들을 모으면서 저작권에 대해서도 주의해야한다.


프로토타입 개발 (2달) : 
팀원끼리 역할을 분담하여 크게 4가지로 구분하여 인공지능개발, 백엔드 개발, 프론트엔드 개발, 데이터관리로 나누어 진행할 예정이다. 
 ● 인공지능 개발 : GPT-4, LLAMA 기반의 생성형 AI 모델 설계 및 API 연동, 데이터학습
 ● 백엔드 개발: Flask를 사용해 서버 구축, API 개발, AI 모델과의 통신, 데이터베이스 설계, 보안 설정
 ● 프론트엔드 개발: CSS를 이용해 UI/UX 설계, React를 이용한 클라이언트-서버 통신, 사용자 인터페이스 개발
 ● 데이터 관리: 데이터 수집, 전처리, DB 설계, AI 학습용 데이터 제공
 협업을 효율적으로 하기 위해 github를 이용해 버전관리 및 서로 코드를 교환하도록 만들것이다. github 사용 도중 충돌 방지를 위해 작업 이력 관리 및 코드리뷰를 통해 충돌을 방지하고자 한다.
 예상 일정은 대략 9주 정도로 프로토타입 개발에 힘을 쓸 생각이다. 3주 간격으로 개인별 개발, 두 개발자의 협업 개발, 세 개발자 모두 협업으로 이루어지고자 한다.
 ● 1~3주차 : (UI/UX 설계가 최우선) UI설계 및 개발  시작, 기본 페이지 구성, 기본 API 구성, AI 기본 기능 개발, 데이터 수집
 ● 4~6주차 : (서로 협업이 필요한 부분을 개발) : AI의 데이터 분석기능, 백엔드 프론트 엔드의 연결
 ● 7~9주차 : (인공지능을 중심으로 모든 부분 연결) : 데이터베이스와 인공지능, 서버와 인공지능 연결, AI 모델의 최종 통합


테스트 및 개선 (2주) : 
 포로토타입 테스트를 위해서 AI생성 내용이 부적절하거나 AI와의 대화의 흐름이 이상하게 흐르거나 공격적 표현의 필터링을 먼저 확인후 평가 기준을 만들어 응답속도, 정확도, 편의성, 직관성, 유효성을 기준으로 테스트를 진행할것이다. 팀원들의 의견으로는 부족 할 수 있기 때문에 베타테스트를 통해 다양한 사용자의 피드백을 수집하고 개선점을 찾아보고자 한다.

최종 발표 및 제출(1주) : 
 발표 자료 준비를 위해 우선 발표 구성 단계를 만들 생각이다. 가장 먼저 사회적문제에 대한 정의 다음으로는 해결 방법을 찾기 위해 아이디어를 모으는 과정, 해당 해결 방법을 정하게 된 이유, 기존의 해결방법과의 차별점 등을 설명할 생각이다. 세번째로는 생성형 AI의 역할, AI를 만들기 위한 기술, 개발 과정들을 설명할 예정이다. 그리고 네번째 프로토타입을 이용한 시연 영상과 해당 프로그램의 기대효과와 향후 발전 가능성, 실직적 교육 효과에 대해 설명하고자 한다. 영상을 준비하는 이유는 가장 직관적으로 현재 프로그램이 어떤식으로 작동하는지에 대해 볼 수 있는 방법이기 때문에 영상 준비할 생각이다. 마지막으로 질의응답 과정을 통해 준비하지 못한 부분에 대한 보충 설명으로 발표를 마무리할 생각이다.
 마지막 질의응답 과정을 준비하기 위해 기술적 도전과제, 프로그램에서 예상되는 한계점, 프로토타입이 아닌 실제로 구현할 경우 예상되는 문제들에 대한 해결방법을 미리 준비할것이다.




(25.03.28)
아이디어 구체화 (2주) :
 "사회적 문제 해결을 위한 생성형 AI활용" 이라는 주제에 맞는 아이디어를 모으기 위해 처음에는 사회적 문제에는 무엇이 있을까 라는 내용으로 브레인 스토밍 시간을 가질 생각으로, 여러 아이디어를 종합하여 팀원 모두가 만족하는 아이디어를 찾는것이 목표이다. 사회적 문제를 정한 이후 또 다시 해결 방법을 생각해야한다. 해결 방법이 문제 해결에 직접적인 도움이 되는지, 브레인 스토밍의 한가지 방법인 스타버스팅, 즉 육하원칙을 이용해 누가, 무엇을, 언제, 어디서, 왜, 어떻게를 기반으로 의견을 종합한 이후 우선순위를 정해 해당 아이디어가 적합한지 맞춰볼 생각이다. 창의성, 주제 적합성, 문제해결의 효과성, 구현 가능성, 사용 가능성에 맞춰 적합성을 맞춰 아이디어를 선정할 것이다.  
 뼈대를 만들었으니 살을 붙이는 활동인 구체화 단계를 진행할 것이다. 구체화 단계에서는 해당 문제를 해결하기 위한 기존 프로그램에는 어떤것이 존재하고, 해당 프로그램과 우리 아이디어의 차별점은 어떤점에서 다른지, 더 나은 대안책은 없을지, 새롭게 만들 부분은 없을지, 기술적으로 어떤 식으로 접근하면 좋을지를 고민하며 구체화 할 생각이다.


데이터 수집 및 모델 학습 (1달) :
 우선 인공지능을 가장 활용하기 편한 파이썬 언어를 기반으로 만들 예정이며, 우선 아이디어 맞는 생성형 AI를 만들기 위해 데이터를 수집해야한다. 데이터 수집을 위해 국내 교육기관에서 제공하는 어휘 난이도 데이터, 국립 국어원과 교육부에서 제공하는 사전 데이터, 뉴스와 논문에서 자주 등장하는 어려운 단어 리스트 데이터들을 수집하고자 한다. 데이터들을 모으면서 저작권에 대해서도 주의해야한다.
 기존 해결책과 달리 
 한글에 대한 퀴즈를 만들기 위한 데이터는 KoNLPy 라이브러리를 이용하여 초성 퀴즈 만들기, 지문 분석및 요약등에 생성형 ai와 함께 작동한다면 속도적 측면이나 정확성 측면에서도 도움을 줄 수 있을것으로 예상된다. 

프로토타입 개발 (2달) : 
 팀원끼리 역할을 분담하여 크게 4가지로 구분하여 인공지능개발, 백엔드 개발, 프론트엔드 개발, 데이터관리로 나누어 진행할 예정이다. 인공지능 개발자는 GPT-4와 LLAMA를 이용해 생성형 AI 모델의 개발과 API 연동, 데이터 학습을 각 개발 분야와 함께 협업을 하고, 백엔드 개발자는 Flask를 이용해 서버구축, 데이터베이스 설계, AI모델의 API연동, 앱 응답처리를 함께 처리를 하고, 프론트엔드 개발자는 UI개발, API 응답처리, 앱 응답처리를 처리하고, 데이터 관리자는 데이터 수집, 데이터베이스 설계, 데이터 학습의 역할들을 맡아 서로 보완하며 개발하고자한다. 협업을 효율적으로 하기 위해 github를 이용해 버전관리 및 서로 코드를 교환하도록 만들것이다. 
 예상일정은 1~2주차에는 UI설계 및 개발  시작 기본 페이지 구성, 기본 API 구성, AI 기본 기능 개발이 이루어질 것이다. 3~4주차에는 서로 협업이 필요한 부분을 개발할 것이며 AI의 데이터 분석기능, 백엔드 프론트 엔드의 연결 등이 이루어질 예정이다. 5~6주차에는 인공지능 개발을 중심으로 다른 부분을 다 연결하고자 한다. 생성형 AI는 사용자의 관심분야의 데이터를 이용해 지문을 만들기 위한 데이터 관리, 데이터베이스속 난이도별 어휘 리스트를 이용해 지문속에 단어를 바꿀 수 있도록 만들기 위해 데이터 베이스와 인공지능의 연결이 주요 관건이다. 

테스트 및 개선 (2주) : 
 프로토타입 테스트에서는 AI생성 내용이 부적절하거나 AI와의 대화의 흐름이 이상하게 흐르거나 공격적 표현의 필터링, 답변에 대한 정확성, 지문을 만드는데 걸리는 시간, UI가 직관적이고 편리함을 가지고 있는지 확인해야하며, 팀원들만의 의견으로는 부족 할 수 있어 여러 사람들에게 사용해본 이후 개선점을 찾아보고자 한다. 

최종 발표 및 제출(1주) : 
 발표 자료 준비를 위해 우선 발표 구성 단계를 만들 생각이다. 가장 먼저 사회적문제에 대한 정의 다음으로는 해결 방법을 찾기 위해 아이디어를 모으는 과정, 해당 해결 방법을 정하게 된 이유, 기존의 해결방법과의 차별점 등을 설명할 생각이다. 세번째로는 생성형 AI의 역할, AI를 만들기 위한 기술, 개발 과정들을 설명할 예정이다. 그리고 네번째 프로토타입을 이용한 시연 영상과 해당 프로그램으로 얻을 수 있는 기대효과에 대해 설명하고자 한다. 영상을 준비하는 이유는 가장 직관적으로 현재 프로그램이 어떤식으로 작동하는지에 대해 볼 수 있는 방법이기 때문에 영상 준비할 생각이다. 마지막으로 질의응답 과정을 통해 준비하지 못한 부분에 대한 보충 설명으로 발표를 마무리할 생각이다.
 마지막 질의응답 과정을 준비하기 위해 기술적 부분, 프로그램에서 예상되는 한계점, 프로토타입이 아닌 실제로 구현할 경우 예상되는 문제들에 대한 해결방법을 미리 준비할것이다.


 최종 테스트를 거친 프로토타입과 지금까지 작성한 회의록을 기반으로 해당 프로젝트를 만들기로 하게 된 사회적문제,  사용한 기술들을 선택한 이유, 여러 시행착오들을 통해 어떤점을 고치게 되었는지에 대한 내용을 담아 프레젠테이션을 준비하고  


아이디어 구체화 (2주) :
 "사회적 문제 해결을 위한 생성형 AI활용" 이라는 주제에 맞는 아이디어를 모으기 위해 처음에는 사회적 문제에는 무엇이 있을까 라는 내용으로 브레인 스토밍 시간을 가질 생각으로, 여러 아이디어를 종합하여 팀원 모두가 만족하는 아이디어를 찾는것이 목표이다. 사회적 문제를 정한 이후 또 다시 해결 방법을 생각해야한다. 해결 방법이 문제 해결에 직접적인 도움이 되는지, 브레인 스토밍의 한가지 방법인 스타버스팅, 즉 육하원칙을 이용해 누가, 무엇을, 언제, 어디서, 왜, 어떻게를 기반으로 의견을 종합한 이후 우선순위를 정해 해당 아이디어가 적합한지 맞춰볼 생각이다. 창의성, 주제 적합성, 문제해결의 효과성, 구현 가능성, 사용 가능성에 맞춰 적합성을 맞춰 아이디어를 선정할 것이다.  


프로토타입 개발 (2달) : 
 팀원끼리 역할을 분담하여 크게 4가지로 구분하여 인공지능개발, 백엔드 개발, 프론트엔드 개발, 데이터관리로 나누어 진행할 예정이다. 인공지능 개발자는 GPT-4와 LLAMA를 이용해 생성형 AI 모델의 개발과 API 연동, 데이터 학습을 각 개발 분야와 함께 협업을 하고, 백엔드 개발자는 Flask를 이용해 서버구축, 데이터베이스 설계, AI모델의 API연동, 앱 응답처리를 함께 처리를 하고, 프론트엔드 개발자는 UI개발, API 응답처리, 앱 응답처리를 처리하고, 데이터 관리자는 데이터 수집, 데이터베이스 설계, 데이터 학습의 역할들을 맡아 서로 보완하며 개발하고자한다. 협업을 효율적으로 하기 위해 github를 이용해 버전관리 및 서로 코드를 교환하도록 만들것이다. github 사용 도중 충돌 방지를 위해 작업 이력 관리 및 코드리뷰를 통해 충돌을 방지하고자 한다.
 예상일정은 1~2주차에는 UI설계 및 개발  시작 기본 페이지 구성, 기본 API 구성, AI 기본 기능 개발이 이루어질 것이다. 3~4주차에는 서로 협업이 필요한 부분을 개발할 것이며 AI의 데이터 분석기능, 백엔드 프론트 엔드의 연결 등이 이루어질 예정이다. 5~6주차에는 인공지능 개발을 중심으로 다른 부분을 다 연결하고자 한다. 생성형 AI는 사용자의 관심분야의 데이터를 이용해 지문을 만들기 위한 데이터 관리, 데이터베이스속 난이도별 어휘 리스트를 이용해 지문속에 단어를 바꿀 수 있도록 만들기 위해 데이터 베이스와 인공지능의 연결이 주요 관건이다. 











아이디어 구체화 (3.21 ~ 3.25) :
 첫날에는 "사회적 문제 해결을 위한 생성형 AI활용" 주제에 대한 아이디어를 모으기 위해 브레인 스토밍 시간을 가졌다. 브레인 스토밍 시간에 "시각장애인을 위한 점자 대신 읽어주는 생성형 AI", "도파민 중독 억제를 위한 추천 알고리즘", "개인정보 보호 관리 AI", "악플 필러팅 생성형 AI" 등 여러 의견이 나왔으나 시간이 남은 만큼 다음 회의까지 각자 3개씩 생각해오기로 했다. 다음 회의에서는 준비해 온 아이디어를 모두에게 소개하는 시간을 가지고 투표를 통해 주제를 선정하였다. 결국 최다 투표였던 "학생들의 문해력 향상을 위한 교육 프로그램"이라는 주제로 진행하게 되었다.
 주제가 정해지니 다음은 구체화 단계를 진행했다. 우선 유사한 프로그램이 있는지 확인하기 위해 여러 교육 프로그램들을 확인 하였으며 각 프로그램들의 차이점, 한계점들을 정리하여 어떠한 점이 사용자들에게 불편하고 필요한지 확인하고 차별점을 만들고자 하였다. 이제 방향성을 잡았으니 뼈를 만들 단계이다. 우선 해결 방안을 생각해보았다. 여러가지의 의견을 들어보고 생성형 AI를 가장 활용할 수 있는 의견으로 학생들에게 관심을 가질 수 있는 지문을 만들어 문해력 향상을 독려하자 라는 의견으로 좁혀졌으며, 이를 기반으로 만든 지문에서 단어를 다른 동의어로 만들기, 빈칸을 만들어 알맞는 단어 찾기, 지문에 대한 내용을 이야기하는 대화를 만들어 지문에 대해 얼마나 이해하였는지 확인하는 과정을 추가하였다. 마지막으로 글을 읽으면서도 이해가 되지 않는 부분은 실시간으로 질문할 수 있도록 실시간 질의응답 AI까지 의견을 종합하였다.
 

아이디어 구체화 (2주) :
 "사회적 문제 해결을 위한 생성형 AI활용" 이라는 주제에 맞는 아이디어를 모으기 위해 처음에는 사회적 문제에는 무엇이 있을까 라는 내용으로 브레인 스토밍 시간을 가질 생각으로, 여러 아이디어를 종합하여 팀원 모두가 만족하는 아이디어를 찾는것이 목표이다. 사회적 문제를 정한 이후 또 다시 해결 방법을 생각해야한다. 해결 방법이 문제 해결에 직접적인 도움이 되는지, 브레인 스토밍의 한가지 방법인 스타버스팅, 즉 육하원칙을 이용해 누가, 무엇을, 언제, 어디서, 왜, 어떻게를 기반으로 의견을 종합한 이후 우선순위를 정해 해당 아이디어가 적합한지 맞춰볼 생각이다. 창의성, 주제 적합성, 문제해결의 효과성, 구현 가능성, 사용 가능성에 맞춰 적합성을 맞춰 아이디어를 선정할 것이다.  



<성찬의 설명>
인공지능 : GPT-4, LLAMA 모델 생성형 모델 -> RAG 포함이 안되어 있다.

RAG을 적용하기위해 LangChain 사용(외부 검색 엔진을 사용, 데이터베이스 연결)

KoNLPy 라이브러리 : 한국어 문장 학습 라이브러리
정리 : 최종적으로는 RAG 기반의 AI 모델을 통해 사용자가 신뢰할 수 있는 최신 정보를 제공받을 수 있도록 하고, 대화 이력을 활용한 개인 맞춤형 학습 경험을 지원할 수 있도록 하겠습니다.


<참고자료>
gpt-4를 이용한 인공지능 앱 개발
https://velog.io/@corone_hi/GPT-4%EC%99%80-%EC%B1%97GPT%EC%9D%98-%ED%95%B5%EC%8B%AC-%EC%9A%94%EC%86%8C


